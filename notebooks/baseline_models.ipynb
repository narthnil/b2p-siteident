{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependant packages for data loader\n",
    "# !pip install torch\n",
    "# !pip install geopandas\n",
    "# !pip install rasterio\n",
    "# !pip install torchvision\n",
    "# !pip install geographiclib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools \n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "from scipy import ndimage\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.data.bridge_site import METADATA, TRAIN_DATA, get_dataloaders, DATA_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting the file paths from ./data/[...] to ../data/[...]\n",
    "metadata = dict(METADATA)\n",
    "for country in metadata:\n",
    "    md = metadata[country]\n",
    "    for data_name in md:\n",
    "        data = md[data_name]\n",
    "        data[\"fp\"] = os.path.join(\"../\", data[\"fp\"])\n",
    "\n",
    "train_data = dict(TRAIN_DATA)\n",
    "for version in train_data:\n",
    "    for tile_size in train_data[version]:\n",
    "        train_data[version][tile_size] = os.path.join(\n",
    "            \"../\", train_data[version][tile_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-bb852e1a045a>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-bb852e1a045a>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    batch_size=64, tile_size=tile_size train_data=train_data,\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def convert_to_np(data):\n",
    "    \"\"\"converts data to numpy array\n",
    "    \n",
    "    params:\n",
    "    split <dataset from loader>: this can be -\n",
    "           dataloader_train,\n",
    "           dataloader_validation,\n",
    "           dataloader_test,\n",
    "           dataloader_test_rw, or\n",
    "           dataloader_test_ug\n",
    "           \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    all_lab = []\n",
    "    for img, lab in data:\n",
    "        all_data.append(img)\n",
    "        all_lab.append(lab)\n",
    "\n",
    "    all_data = torch.cat(all_data, 0).numpy()\n",
    "    all_lab = torch.cat(all_lab, 0).numpy()\n",
    "\n",
    "    print('shape as numpy array ', all_data.shape)\n",
    "    # (1630, 9, 48, 48) -> 1630 instances, 9 channels, 48x48 tile pixels\n",
    "    # print(all_lab.shape)\n",
    "    # (1630,)\n",
    "    return all_data\n",
    "    \n",
    "\n",
    "def load_data(tile_size, version, modalities):\n",
    "    \"\"\"get data loaders\"\"\"\n",
    "    (dataloader_train, dataloader_validation, dataloader_test,\n",
    " dataloader_test_rw, dataloader_test_ug, dataloader_unlab) = get_dataloaders(\n",
    "    batch_size=64, tile_size=tile_size train_data=train_data,\n",
    "    train_metadata=metadata, transform=False, num_workers=0,\n",
    "    stats_fp=\"../data/ground_truth/stats.json\", use_augment=False,\n",
    "    drop_last=False, data_version=version\n",
    ")\n",
    "    train = convert_to_no(dataloader_train)\n",
    "    val = convert_to_no(dataloader_validation)\n",
    "    test = convert_to_no(dataloader_test)\n",
    "    test_ug = convert_to_no(dataloader_test_ug\n",
    "    test_rw = convert_to_no(dataloader_test_rw)\n",
    "    \n",
    "    if modalities == 'limited':\n",
    "        pass # do some indexing\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    # train with three different seeds\n",
    "                            \n",
    "    # predict for each seed model\n",
    "    \n",
    "    # get score and ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model variables\n",
    "\n",
    "TILE_SIZE= 1200  # or '600' or '300'\n",
    "VERSION = 'v1'  # or 'v2'\n",
    "MODALITIES = 'all'  # or 'limited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '300m_v1'\n",
    "directory = '/home/rachel/Documents/projects/probono/data_as_numpy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(directory + data + '_train.npy')\n",
    "val = np.load(directory + data + '_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1630, 9, 12, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 9, 12, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models:\n",
    "Model for each tile size and version: 300v1, 300v2, 600v1, 600v2, 1200v1, 1200v2\n",
    "\n",
    "scores for all the test tests:\n",
    "\n",
    "ALL MODES\n",
    "1200v1 both countries: f1+/-ste , bacc+/-ste # \n",
    "1200v1 rwanda:         f1+/-ste , bacc+/-ste # i get the ste by useing different seeds to run the code \n",
    "1200v1 ug countries:   f1+/-ste , bacc+/-ste\n",
    "600v1 both countries:  f1+/-ste , bacc+/-ste\n",
    "600v1 rwanda:          f1+/-ste , bacc+/-ste\n",
    "600v1 ug :             f1+/-ste , bacc+/-ste\n",
    "300v1 both countries:  f1+/-ste , bacc+/-ste\n",
    "300v1 rwanda:          f1+/-ste , bacc+/-ste\n",
    "300v1 ug countries:    f1+/-ste , bacc+/-ste\n",
    "1200v2 both countries: f1+/-ste , bacc+/-ste \n",
    "1200v2 rwanda:         f1+/-ste , bacc+/-ste\n",
    "1200v2 ug countries:   f1+/-ste , bacc+/-ste\n",
    "600v2 both countries:  f1+/-ste , bacc+/-ste\n",
    "600v2 rwanda:          f1+/-ste , bacc+/-ste\n",
    "600v2 ug countries:    f1+/-ste , bacc+/-ste\n",
    "300v2 both countries:  f1+/-ste , bacc+/-ste\n",
    "300v2 rwanda:          f1+/-ste , bacc+/-ste\n",
    "300v2 ug countries:    f1+/-ste , bacc+/-ste\n",
    "\n",
    "LIMITED MODES\n",
    "1200v1 both countries: f1+/-ste , bacc+/-ste # \n",
    "1200v1 rwanda:         f1+/-ste , bacc+/-ste # i get the ste by useing different seeds to run the code \n",
    "1200v1 ug countries:   f1+/-ste , bacc+/-ste\n",
    "600v1 both countries:  f1+/-ste , bacc+/-ste\n",
    "600v1 rwanda:          f1+/-ste , bacc+/-ste\n",
    "600v1 ug :             f1+/-ste , bacc+/-ste\n",
    "300v1 both countries:  f1+/-ste , bacc+/-ste\n",
    "300v1 rwanda:          f1+/-ste , bacc+/-ste\n",
    "300v1 ug countries:    f1+/-ste , bacc+/-ste\n",
    "1200v2 both countries: f1+/-ste , bacc+/-ste \n",
    "1200v2 rwanda:         f1+/-ste , bacc+/-ste\n",
    "1200v2 ug countries:   f1+/-ste , bacc+/-ste\n",
    "600v2 both countries:  f1+/-ste , bacc+/-ste\n",
    "600v2 rwanda:          f1+/-ste , bacc+/-ste\n",
    "600v2 ug countries:    f1+/-ste , bacc+/-ste\n",
    "300v2 both countries:  f1+/-ste , bacc+/-ste\n",
    "300v2 rwanda:          f1+/-ste , bacc+/-ste\n",
    "300v2 ug countries:    f1+/-ste , bacc+/-ste\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes from meeting with linh:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add to the notebook and work flow the  dataloader  from other notebook. at the first step in training  and predicting so that it can be re ran if we want to use new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do all the modes and results above for bothe ALL MODALITIES and LIMITED MMODALITIES<br>\n",
    "- all modalities are listed in the data loader scripts<br>\n",
    "- limited are : admin bountries, osm img, waterways, ans slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "send lin the resutls as soon as possibl so we can see if they are too good like last time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "push changes to notebok to github so that linh can re run the notebook if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
